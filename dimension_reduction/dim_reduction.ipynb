{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a15301d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170a6bef",
   "metadata": {},
   "source": [
    "# Dimensionality reduction\n",
    "SVD, PCA, NMF, and all that"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e66fcf",
   "metadata": {},
   "source": [
    "### Singular value decomposition (SVD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd9b01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_olivetti_faces \n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "from numpy.random import RandomState # random seed\n",
    "rng = RandomState(0) # set seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18073ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_row, n_col = 6, 4 # how many components to plot\n",
    "n_components = n_row * n_col \n",
    "image_shape = (64, 64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9bd64d",
   "metadata": {},
   "source": [
    "Dataset contains 400 faces that have been cropped to 64x64 (4096 raveled) images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44f2ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "faces, _ = fetch_olivetti_faces(return_X_y=True, shuffle=True,\n",
    "                                random_state=rng)\n",
    "n_samples, n_features = faces.shape\n",
    "print(n_samples,n_features)\n",
    "print(np.sqrt(n_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231faa0b",
   "metadata": {},
   "source": [
    "Plot a sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf97b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a sample\n",
    "plt.figure(figsize=(5, 8))\n",
    "for face_id, face in enumerate(faces[:n_components]):\n",
    "    plt.subplot(n_row,n_col,face_id+1)\n",
    "    plt.imshow(face.reshape(image_shape), cmap='gray')\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a24f76",
   "metadata": {},
   "source": [
    "Mean center the data and show mean face:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a092fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mn_face = faces.mean(axis=0)\n",
    "faces_centered = faces - mn_face\n",
    "\n",
    "plt.figure(figsize=(3,2))\n",
    "plt.imshow(mn_face.reshape(image_shape), cmap='gray');\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6d0aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,8))\n",
    "for face_id, face in enumerate(faces_centered[:n_components]):\n",
    "  plt.subplot(n_row, n_col, face_id+1)\n",
    "  plt.imshow(face.reshape(image_shape), cmap='gray')\n",
    "  plt.axis('off')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca98f56",
   "metadata": {},
   "source": [
    "Do SVD:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9f29c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "U, S, VT = np.linalg.svd(faces_centered.T, full_matrices=False) # does on truncated\n",
    "perc_var_exp = S/np.sum(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c60e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "perc_var_exp = S/np.sum(S)\n",
    "plt.plot(100*np.cumsum(perc_var_exp[:20]), marker='.');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af26c6a",
   "metadata": {},
   "source": [
    "Plot the average face and the first few eigenfaces (first few columns of U).\n",
    "\n",
    "Title shows column number and percent variance explained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a584e122",
   "metadata": {},
   "outputs": [],
   "source": [
    "eigen_rows = 5\n",
    "eigen_cols = 4\n",
    "n_eigenplots = eigen_rows*eigen_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c35e3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,8))\n",
    "for eigen_id, eigenface in enumerate(U[:,:n_eigenplots].T):\n",
    "   var_exp = perc_var_exp[eigen_id]\n",
    "   plt.subplot(n_row,n_col,eigen_id+1)\n",
    "   plt.title(f\"{eigen_id+1}: {100*var_exp:0.2f}\")\n",
    "   plt.imshow(eigenface.reshape(image_shape), cmap='gray') # seismic\n",
    "   plt.axis('off')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8d86a8",
   "metadata": {},
   "source": [
    "Show color-coded by positive (red)/negative(blue):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df820f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import colors\n",
    "divnorm=colors.TwoSlopeNorm(vcenter=0.)\n",
    "plt.figure(figsize=(5,8))\n",
    "for eigen_id, eigenface in enumerate(U[:,:n_eigenplots].T):\n",
    "   var_exp = perc_var_exp[eigen_id]\n",
    "   plt.subplot(n_row,n_col,eigen_id+1)\n",
    "   plt.title(f\"{eigen_id+1}: {100*var_exp:0.2f}\")\n",
    "   plt.imshow(eigenface.reshape(image_shape), cmap='bwr', norm=divnorm) # coolwarm/bwr\n",
    "   plt.axis('off')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d01a57",
   "metadata": {},
   "source": [
    "Plot an arbitrary eigenface (there are 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046d2d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "ghost_ind = 300\n",
    "var_exp = perc_var_exp[ghost_ind]\n",
    "ghost_face = U[:,ghost_ind].reshape(image_shape)\n",
    "\n",
    "f, ax = plt.subplots(figsize=(3,3))\n",
    "ax.imshow(ghost_face, cmap='bwr', norm=divnorm)\n",
    "ax.axis('off')\n",
    "ax.set_title(f\"{ghost_ind} ({100*var_exp: 0.2f})\", fontsize=12);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a3daa2",
   "metadata": {},
   "source": [
    "## Project arbitrary image to lower-rank eigenface\n",
    "\n",
    "We are just faces from image set here, but you can do any image (if it is resized to correct shape): a shoe, a dog, a building, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cca8654",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_ind = 2\n",
    "## Now show eigenface reconstruction of image that was omitted from test set\n",
    "test_face = faces[face_ind, :] # First face of person 37\n",
    "test_centered = faces_centered[face_ind, :]\n",
    "test_face.shape, test_centered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fb82c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax1, ax2) = plt.subplots(1,2, figsize=(6,4))\n",
    "ax1.imshow(test_face.reshape(image_shape), cmap='gray')\n",
    "ax1.set_title('Original')\n",
    "ax1.axis('off');\n",
    "\n",
    "ax2.imshow(test_centered.reshape(image_shape), cmap='gray')\n",
    "ax2.set_title('Centered')\n",
    "ax2.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05df657",
   "metadata": {},
   "source": [
    "Reconstruct to different rank-p approximations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4785112c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "p_list = [1, 2, 5, 10, 20, 25, 30, 35, 40, 50, 100, 200, 300, 400]\n",
    "reconstructed_faces = []\n",
    "for p in p_list:\n",
    "    # reconstructed face U U^T Face\n",
    "    xhat_p = mn_face + U[:,:p] @ U[:,:p].T @ test_centered\n",
    "    reconstructed_faces.append(xhat_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e498f6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2,7, figsize=(12,7))\n",
    "axes = np.ravel(axes)\n",
    "for img_ind in range(len(reconstructed_faces)):\n",
    "    axes[img_ind].imshow(reconstructed_faces[img_ind].reshape(image_shape), cmap='gray')\n",
    "    axes[img_ind].set_title(f\"{p_list[img_ind]}\", fontsize=12)\n",
    "    axes[img_ind].axis('off')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f297046",
   "metadata": {},
   "source": [
    "# Nonnegative matrix factorization (NMF)\n",
    "NMF:\n",
    "- Find two non-negative matrices (W, H) whose product approximates the nonnegative matrix X.\n",
    "- The objective function is minimized with an alternating minimization of W and H.\n",
    "\n",
    "We'll be using scikit-learn implementation, which uses following objective function:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\begin{aligned}\n",
    "L(W, H) &= 0.5 * ||X - WH||_{loss}^2\\\\&\n",
    "+ alpha\\_W * l1\\_ratio * n\\_features * ||vec(W)||_1\\\\&\n",
    "+ alpha\\_H * l1\\_ratio * n\\_samples * ||vec(H)||_1\\\\&\n",
    "+ 0.5 * alpha\\_W * (1 - l1\\_ratio) * n\\_features * ||W||_{Fro}^2\\\\&\n",
    "+ 0.5 * alpha\\_H * (1 - l1\\_ratio) * n\\_samples * ||H||_{Fro}^2\n",
    "\\end{aligned}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Let's ignore the H tearms so let's reduce it to the following by setting $\\alpha_H$ to 0:\n",
    "$$\n",
    "\\begin{align}\n",
    "\\begin{aligned}\n",
    "L(W, H) &= 0.5 * ||X - WH||_{loss}^2\\\\&\n",
    "+ alpha\\_W * l1\\_ratio * n\\_features * ||vec(W)||_1\\\\&\n",
    "+ 0.5 * alpha\\_W * (1 - l1\\_ratio) * n\\_features * ||W||_{Fro}^2\\\\&\n",
    "\\end{aligned}\n",
    "\\end{align}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9b0f22",
   "metadata": {},
   "source": [
    "- The first term is the distance between X and the approximation, which obviously we want to minimize (I'm assuming Frobenius norm, which is the default in scikit-learn's `NMF()`, but you can use other loss functions). \n",
    "- We can regularize using the L1 (absolute value) norm or L2 (Frobenius) norm. We can regularize the new basis matrix W or the mixing coefficient vectors in H. We will focus on W. Most relevant for us, L1 regularization tends to generate sparse parameter sets,  while L2 regularization tends to make them small but not zero/sparse. For instance, see some great answers [here](https://stats.stackexchange.com/questions/45643/why-l1-norm-for-sparse-models), but also many other great discussion across the interwebs. \n",
    "- In the model, the *L1_ratio* determines the balance of L1 and L2 used (if the L1 ratio is 1, then only L1 is used, if it is 0, then only L2 is used). \n",
    "\n",
    "So if we want a sparse face representation, we should set alpha_W very high (say, to 1) and we want to emphasise L1 regularization (naively, we would set *L1_ratio* to 1). \n",
    "\n",
    "Since we don't really care about H sparseness we should be able to set alpha_H to 0 (also, I find in practice that the `NMF` algorithm behavior is extremelly sensitive to `alpha_H` it is just not very well behaved)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b67cb3",
   "metadata": {},
   "source": [
    "### On sparseness\n",
    "Rather than just subjectively judge sparseness, let's quantify it. \n",
    "\n",
    "This is *basically* a measure of how many pixels are being used in a given basis vector, with the wrinkle that if they are all the same value (e.g., all 0.5) then that counts as sparse too -- this is important as this happens quite often, especially if you start tweaking H. So it isn't just a measure of how many zeros are in a vector.\n",
    "\n",
    "Good review paper on this topic : [Comparing Measures of Sparsity](https://ieeexplore.ieee.org/document/5238742):\n",
    "\n",
    "> There are many measures of sparsity. Intuitively, a sparse representation is one in which a small number of coefficients contain a large proportion of the energy. \n",
    "\n",
    "We'll use one useful measure from Hoyer (2004) to compare sparseness of the PCA basis set with that obtained using NMF."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80357d9",
   "metadata": {},
   "source": [
    "### On multiplicative update vs coordinate descent\n",
    "As you will see, there are two algorithms you can choose in scikit-learn to solve the NMF optimization problem: coordinate descent, or multiplicative update.  Deriving multiplicative update rule is [here](https://stats.stackexchange.com/a/352921/17624). \n",
    "\n",
    "In practice, they give pretty different results. I'm going to go with the method developed in Lee and Seung (1999) below, multiplicative update. Caiman uses something else altogether, which is extremely efficient. They all use some version of *biconvex optimization* in which one variable (W) is held fixed, the solver minimizes the other (H), and then vice-versa.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c550d273",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def sparseness_hoyer(x):\n",
    "    \"\"\"\n",
    "    The sparseness of array x is a real number in [0, 1], where sparser array\n",
    "    has value closer to 1. Sparseness is 1 iff the vector contains a single\n",
    "    nonzero component and is equal to 0 iff all components of the vector are \n",
    "    the same\n",
    "        \n",
    "    modified from Hoyer 2004: [sqrt(n)-L1/L2]/[sqrt(n)-1]\n",
    "    \n",
    "    adapted from nimfa package: https://nimfa.biolab.si/\n",
    "    \"\"\"\n",
    "    from math import sqrt # faster than numpy sqrt \n",
    "    eps = np.finfo(x.dtype).eps if 'int' not in str(x.dtype) else 1e-9\n",
    "    \n",
    "    n = x.size\n",
    "\n",
    "    # measure is meant for nmf: things get weird for negative values\n",
    "    if np.min(x) < 0:\n",
    "        x -= np.min(x)\n",
    "        \n",
    "    # patch for array of zeros\n",
    "    if np.allclose(x, np.zeros(x.shape), atol=1e-6):\n",
    "        return 0.0\n",
    "    \n",
    "    L1 = abs(x).sum()\n",
    "    L2 = sqrt(np.multiply(x, x).sum())\n",
    "    sparseness_num = sqrt(n) - (L1 + eps) / (L2 + eps)\n",
    "    sparseness_den = sqrt(n) - 1\n",
    "    \n",
    "    return sparseness_num / sparseness_den\n",
    "\n",
    "def sparseness(array, axis=0):\n",
    "    \"\"\"\n",
    "    Get sparseness of each column of array (or row)\n",
    "    Also returns mean sparseness\n",
    "    \n",
    "    only works for up to 2d\n",
    "    \"\"\"\n",
    "    dims = array.ndim\n",
    "    if dims > 2:\n",
    "        raise ValueError(\"sparseness accepts 1d or 2d arrays\")\n",
    "\n",
    "    elif dims == 1:\n",
    "            sparsity = sparseness_hoyer(array)\n",
    "    elif dims == 2:\n",
    "        if axis == 0:\n",
    "            num_cols = array.shape[1]\n",
    "            sparsity = []\n",
    "            for col in np.arange(num_cols):\n",
    "                col_dat = array[:,col]\n",
    "                col_sparseness = sparseness_hoyer(col_dat)\n",
    "                sparsity.append(col_sparseness)\n",
    "        elif axis == 1: \n",
    "            num_rows = array.shape[0]\n",
    "            sparsity = []\n",
    "            for row in np.arange(num_rows):\n",
    "                row_dat = array[row,:]\n",
    "                row_sparseness = sparseness_hoyer(row_dat)\n",
    "                sparsity.append(row_sparseness)\n",
    "                \n",
    "        sparsity = np.array(sparsity)\n",
    "    mn_sparsity = np.mean(sparsity)\n",
    "    \n",
    "    return sparsity, mn_sparsity\n",
    "            \n",
    "print('done') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e462e3eb",
   "metadata": {},
   "source": [
    "## First run SVD and get sparseness\n",
    "Run this all at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e663c9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_olivetti_faces \n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "faces, _ = fetch_olivetti_faces(return_X_y=True)    \n",
    "mn_face = faces.mean(axis=0)\n",
    "faces_centered = faces - mn_face\n",
    "\n",
    "U, S, VT = np.linalg.svd(faces_centered.T, full_matrices=False)\n",
    "perc_var_exp = S/np.sum(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8fd67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_sparseness, pca_sparseness_mn = sparseness(U);\n",
    "print(pca_sparseness_mn)\n",
    "plt.hist(pca_sparseness, bins=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6eef47",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_row, n_col = 5, 4 \n",
    "image_shape = (64, 64)\n",
    "print('loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25a7186",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,8))\n",
    "for eigen_id, eigenface in enumerate(U[:,:n_row*n_col].T):\n",
    "   var_exp = perc_var_exp[eigen_id]\n",
    "   plt.subplot(n_row,n_col,eigen_id+1)\n",
    "   plt.title(f\"{pca_sparseness[eigen_id]: 0.2f}\")\n",
    "   plt.imshow(eigenface.reshape(image_shape), cmap='gray') # seismic\n",
    "   plt.axis('off')\n",
    "plt.suptitle('PCA', fontsize=16, y=0.98)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85874433",
   "metadata": {},
   "source": [
    "## NMF\n",
    "Let's goooo! \n",
    "\n",
    "There is some repetition of code here so you can run this by itself if you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969583a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_olivetti_faces \n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "faces, _ = fetch_olivetti_faces(return_X_y=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9516059",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 200 \n",
    "alph_W = 0.9  # cd: .9, mu: .9\n",
    "L1_ratio = 0.9 # cd: 0, L1_ratio: 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec05b777-fed8-4bb4-91a7-3f55d700416a",
   "metadata": {},
   "outputs": [],
   "source": [
    "faces.shape, faces_centered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081f1d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "estimator = NMF(k, \n",
    "                init='nndsvdar', # nndsvd\n",
    "                solver='mu', #default is 'cd', use 'mu' if you want parts\n",
    "                max_iter=50,\n",
    "                alpha_W=alph_W,\n",
    "                alpha_H=0, # leave as 0 otherwise typically end up with all zeros\n",
    "                l1_ratio=L1_ratio,\n",
    "                shuffle=True)\n",
    "\n",
    "H = estimator.fit_transform(faces)\n",
    "W = estimator.components_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02846269",
   "metadata": {},
   "source": [
    "Plot the basis faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425cd6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_shape = (64, 64)\n",
    "n_samples, n_features = faces.shape\n",
    "plt.figure(figsize=(5,8))\n",
    "for face_id, face in enumerate(W[:n_row*n_col]):\n",
    "    plt.subplot(n_row, n_col, face_id+1)\n",
    "    face_sparseness = sparseness_hoyer(face)\n",
    "    plt.imshow(face.reshape(image_shape), cmap='gray')\n",
    "    plt.title(f\"{face_sparseness: 0.2f}\")\n",
    "    plt.axis('off')\n",
    "# plt.suptitle('NMF', fontsize=16, y=1)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203fbe72",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_sparseness, w_sparseness_mn = sparseness(W, axis=1);\n",
    "print(f\"Sparseness nmf: {w_sparseness_mn: 0.2f}, PCA: {pca_sparseness_mn: 0.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b54ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure of sparseness of pca vs W\n",
    "plt.figure()\n",
    "plt.hist(w_sparseness, color='blue', bins=100, density=True, alpha=0.4, label='NMF');\n",
    "plt.hist(pca_sparseness, color='red', bins=100, alpha=0.4, density=True, label='PCA');\n",
    "plt.legend(fontsize=12)\n",
    "plt.xlabel('Sparsenss', fontsize=16)\n",
    "plt.ylabel('Density', fontsize=16);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa60fde",
   "metadata": {},
   "source": [
    "Weirdly, initial components are typically lower sparsity. Why?(I don't actually know! Could it have to do with low-rank approximation being optimized? The fact that we didn't run it on centered data? (**Q:** what happens if you run NMF on centered data?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa66d748",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(w_sparseness,\n",
    "        marker='.',\n",
    "        markersize=6,\n",
    "        color='r')\n",
    "plt.xlabel('Component', fontsize=14)\n",
    "plt.ylabel('Sparseness', fontsize=14);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe1fb3b",
   "metadata": {},
   "source": [
    "## NMF with simulated neural data\n",
    "This is adapted partly from a blog post/Matlab code from Bill Connelly:\n",
    "http://www.billconnelly.net/?p=534\n",
    "\n",
    "I wrote it to be interpretable and clear, not efficient or realistic, so I would not use this for doing actual science or simulations!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c27e5d",
   "metadata": {},
   "source": [
    "First create five component templates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392a218f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "num_frames = 1000\n",
    "image_size = 200\n",
    "frame_shape = np.array([image_size, image_size])\n",
    "component_centers = np.array([[40, 40],\n",
    "                              [110, 90],\n",
    "                              [180, 55],\n",
    "                              [60, 135],\n",
    "                              [140, 140]]);\n",
    "component_sigmas = np.array([15, 26.5, 35, 13, 26])\n",
    "num_components = component_centers.shape[0]\n",
    "\n",
    "# create component images\n",
    "x, y = np.meshgrid(np.arange(0, image_size), \n",
    "                   np.arange(0, image_size)) \n",
    "pos = np.dstack((x, y))\n",
    "component_images = []\n",
    "for component_num in np.arange(num_components):\n",
    "    component_mean = component_centers[component_num]\n",
    "    component_sigma = component_sigmas[component_num]\n",
    "    gauss_rep = multivariate_normal(component_mean, component_sigma)\n",
    "    gauss_img = gauss_rep.pdf(pos)\n",
    "    component_images.append(gauss_img)\n",
    "component_images = np.array(component_images)\n",
    "print(component_images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15d8171",
   "metadata": {},
   "source": [
    "Show the component templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246edbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,3))\n",
    "\n",
    "for ind, component_image in enumerate(component_images):\n",
    "    plt.subplot(1,5,ind+1)\n",
    "    plt.imshow(component_image, cmap='hot')\n",
    "    plt.axis('off');\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7573ac",
   "metadata": {},
   "source": [
    "Simulate their time course as instant onset, exponential decay:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d7024e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tau = 10 # 4\n",
    "max_amp = 255  # just to make saving as uint8 in opencv simple\n",
    "amps_all = []\n",
    "\n",
    "for component_num in np.arange(num_components):\n",
    "    amps = []\n",
    "    amp = 0\n",
    "    for time_step in np.arange(num_frames):\n",
    "        if np.random.uniform(0,1) > 0.98:  #0.98\n",
    "            amp = max_amp\n",
    "        else:\n",
    "            amp = np.max(np.array([amp - amp/tau, 0]));\n",
    "        amps.append(amp)\n",
    "    amps = np.array(amps)\n",
    "    amps_all.append(amps)\n",
    "amps_all = np.array(amps_all)\n",
    "\n",
    "plt.figure(figsize=(3, 7))\n",
    "for ind, signal in enumerate(amps_all):\n",
    "    plt.subplot(5,1,ind+1)\n",
    "    plt.plot(amps_all[ind], color='k', linewidth=0.75)\n",
    "    plt.title(f\"Component {ind+1}\", fontsize=8)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71dd6715",
   "metadata": {},
   "source": [
    "Simulate calcium movie that combines signals from all components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b74d637",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie = np.zeros((num_frames, image_size, image_size))\n",
    "for frame_num in np.arange(num_frames):\n",
    "    component0 = amps_all[0][frame_num]*component_images[0]\n",
    "    component1 = amps_all[1][frame_num]*component_images[1]\n",
    "    component2 = amps_all[2][frame_num]*component_images[2]\n",
    "    component3 = amps_all[3][frame_num]*component_images[3]\n",
    "    component4 = amps_all[4][frame_num]*component_images[4]\n",
    "    movie[frame_num] = component0 + component1 + component2 + component3 + component4 \n",
    "    \n",
    "movie = movie\n",
    "movie_noise = 1.*np.random.rand(movie.shape[0], movie.shape[1], movie.shape[1])\n",
    "movie_noised = movie + movie_noise\n",
    "\n",
    "print('loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ef7310",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastplotlib import ImageWidget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4622bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "iw = ImageWidget(\n",
    "    data=movie_noised, \n",
    "    slider_dims=[\"t\"],\n",
    "    vmin_vmax_sliders=True,\n",
    "    cmap=\"inferno\")\n",
    "iw.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677adb4b",
   "metadata": {},
   "source": [
    "Exercise for reader: imagewidget and line stack."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65d4a54",
   "metadata": {},
   "source": [
    "Optionally, save movie as mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33dee15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "fps = 25\n",
    "out = cv2.VideoWriter('synthetic_ca.mp4', \n",
    "                      cv2.VideoWriter_fourcc(*'DIVX'),  #mp4v (encoding)\n",
    "                      fps, \n",
    "                      (image_size, image_size), \n",
    "                      False) # is_color\n",
    "for frame in movie:\n",
    "    out.write(frame)\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad730ff3",
   "metadata": {},
   "source": [
    "## Convert movie to something you can use for NMF\n",
    "Just like you converted each face to a single array and ended up with each face a single vector (so with 400 faces, you ended up with a num_images x num_pixels array), here we have each frame as a single vector so will end up with a num_frames by num_pixels array. First, reshape the array, and then run NMF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a611fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pixels = image_size*image_size\n",
    "reshaped_movie = np.reshape(movie, (num_frames, num_pixels));\n",
    "reshaped_movie.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a260fa",
   "metadata": {},
   "source": [
    "Run NMF on this 2d-array-ified movie:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59129579",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "\n",
    "k = 5\n",
    "alph_W = 0.9 \n",
    "L1_ratio = 0.9 \n",
    "print('loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591408d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time   \n",
    "estimator = NMF(k, \n",
    "                init='nndsvdar', \n",
    "                solver='mu',\n",
    "                max_iter=500,\n",
    "                alpha_W=alph_W,\n",
    "                alpha_H=0, \n",
    "                l1_ratio=L1_ratio,\n",
    "                shuffle=True)\n",
    "\n",
    "H = estimator.fit_transform(reshaped_movie)\n",
    "W = estimator.components_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e795308e",
   "metadata": {},
   "source": [
    "Plot components and estimated components in one figure (note NMF is not ordered, so they likely won't match up):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5394707f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "w_sum = np.zeros(frame_shape)\n",
    "# Actual components\n",
    "for component_id, component_image in enumerate(component_images):\n",
    "    plt.subplot(2,5,component_id+1)\n",
    "    plt.imshow(component_image, cmap='hot')\n",
    "    plt.title(f\"Component {component_id}\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "# Estimated components\n",
    "for component_id, component in enumerate(W[:5]):\n",
    "    plt.subplot(2, 5, component_id+6)\n",
    "    w_frame = component.reshape(frame_shape)\n",
    "    plt.imshow(w_frame, cmap='hot')\n",
    "    w_sum += w_frame\n",
    "    plt.title(f\"Estimate {component_id}\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "plt.suptitle('Actual and Estimated Components', fontsize=16, y=1)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fab4c2c",
   "metadata": {},
   "source": [
    "Plot time course of the matching components (you need to select indices of estimate and actual):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d56613",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_ind = 0\n",
    "estimate_ind = 2\n",
    "print('loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cc4992",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.title(f\"Actual {actual_ind}\")\n",
    "plt.plot(amps_all[actual_ind, :], color='r', linewidth=1.75);\n",
    "plt.xlim(0, 1000)\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(H[:, estimate_ind], color='b', linewidth=1.75)\n",
    "plt.title(f\"Estimate {estimate_ind}\")\n",
    "plt.xlim(0, 1000)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc9a3fb",
   "metadata": {},
   "source": [
    "## Exercises for the motivated:\n",
    "- Add contour plots for the actual/estimates, and inspect overlap.\n",
    "- Automate the mapping from estimate to actual.\n",
    "- Make a more realistic model of the components (how? how was our model of individual components simplified and unrealistic?)\n",
    "- Add background noise model.\n",
    "\n",
    "Add what point does the off-the-shelf NMF break down, latch onto noise, does the selection of the components become tougher, or the components become harder to interpret?\n",
    "\n",
    "It's because of such realism that we see in actual neural recordings that *constrained* NMF comes in. As we saw, even NMF from scikit-learn is quite a bit more complex than simply minimizing the distance between X and WH. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffc85e0-1d1c-4363-98dc-444de51d4a45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
